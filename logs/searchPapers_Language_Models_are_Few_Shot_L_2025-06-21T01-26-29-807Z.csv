timestamp,endpoint,query,paperId,title,year,authors,venue,citations,url
2025-06-21T01-26-29-807Z,searchPapers,Language Models are Few Shot Learners,90abbc2cf38462b954ae1b772fac9532e2ccd8b0,Language Models are Few-Shot Learners,2020,Tom B. Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; J. Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; T. Henighan; R. Child; A. Ramesh; Daniel M. Ziegler; Jeff Wu; Clemens Winter; Christopher Hesse; Mark Chen; Eric Sigler; Ma-teusz Litwin; Scott Gray; Benjamin Chess; Jack Clark; Christopher Berner; Sam McCandlish; Alec Radford; I. Sutskever; Dario Amodei,Neural Information Processing Systems,42352,https://www.semanticscholar.org/paper/90abbc2cf38462b954ae1b772fac9532e2ccd8b0
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,236445f0a3b1e30b2542e5e64616ff6a8af7e3ea,Language Models are Few-shot Learners for Prognostic Prediction,2023,Zekai Chen; Mariann Micsinai Balan; Kevin Brown,arXiv.org,90,https://www.semanticscholar.org/paper/236445f0a3b1e30b2542e5e64616ff6a8af7e3ea
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,f30444fbb6ad806168e2564db4815cd27faa7fd9,It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners,2020,Timo Schick; Hinrich Schütze,North American Chapter of the Association for Computational Linguistics,974,https://www.semanticscholar.org/paper/f30444fbb6ad806168e2564db4815cd27faa7fd9
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,ff0b2681d7b05e16c46dfb71d980cc2f605907cd,Finetuned Language Models Are Zero-Shot Learners,2021,Jason Wei; Maarten Bosma; Vincent Zhao; Kelvin Guu; Adams Wei Yu; Brian Lester; Nan Du; Andrew M. Dai; Quoc V. Le,International Conference on Learning Representations,3783,https://www.semanticscholar.org/paper/ff0b2681d7b05e16c46dfb71d980cc2f605907cd
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,85e7d63f75c0916bd350a229e040c5fbb1472e7a,Making Pre-trained Language Models Better Few-shot Learners,2021,Tianyu Gao; Adam Fisch; Danqi Chen,Annual Meeting of the Association for Computational Linguistics,1971,https://www.semanticscholar.org/paper/85e7d63f75c0916bd350a229e040c5fbb1472e7a
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,6dd44624ac912fb50c21c691806ee52d27e73abb,Large Language Models are Few-Shot Health Learners,2023,Xin Liu; Daniel J. McDuff; G. Kovács; I. Galatzer-Levy; Jacob Sunshine; Jiening Zhan; M. Poh; Shun Liao; P. Achille; Shwetak N. Patel,arXiv.org,113,https://www.semanticscholar.org/paper/6dd44624ac912fb50c21c691806ee52d27e73abb
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,42fc019b2668c9d9d984154d4c57f6c6d5a91619,Language Models are Few-shot Multilingual Learners,2021,Genta Indra Winata; Andrea Madotto; Zhaojiang Lin; Rosanne Liu; J. Yosinski; Pascale Fung,MRL,137,https://www.semanticscholar.org/paper/42fc019b2668c9d9d984154d4c57f6c6d5a91619
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,9405cc0d6169988371b2755e573cc28650d14dfe,Language Models are Unsupervised Multitask Learners,2019,Alec Radford; Jeff Wu; R. Child; D. Luan; Dario Amodei; I. Sutskever,,23071,https://www.semanticscholar.org/paper/9405cc0d6169988371b2755e573cc28650d14dfe
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,e7ad08848d5d7c5c47673ffe0da06af443643bda,Large Language Models are Zero-Shot Reasoners,2022,Takeshi Kojima; S. Gu; Machel Reid; Yutaka Matsuo; Yusuke Iwasawa,Neural Information Processing Systems,4495,https://www.semanticscholar.org/paper/e7ad08848d5d7c5c47673ffe0da06af443643bda
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,b65b7f480a61d3dd31d8117b349cabc87c8ccf6c,Bidirectional Language Models Are Also Few-shot Learners,2022,Ajay Patel; Bryan Li; Mohammad Sadegh Rasooli; Noah Constant; Colin Raffel; Chris Callison-Burch,International Conference on Learning Representations,47,https://www.semanticscholar.org/paper/b65b7f480a61d3dd31d8117b349cabc87c8ccf6c
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,9b56086e420ecb216f85d408a25264f640e46705,Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners,2021,Ningyu Zhang; Luoqiu Li; Xiang Chen; Shumin Deng; Zhen Bi; Chuanqi Tan; Fei Huang; Huajun Chen,International Conference on Learning Representations,179,https://www.semanticscholar.org/paper/9b56086e420ecb216f85d408a25264f640e46705
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,86d0d3855f94105e25d81cab9f3d269c6062a9c4,Selective Annotation Makes Language Models Better Few-Shot Learners,2022,Hongjin Su; Jungo Kasai; Chen Henry Wu; Weijia Shi; Tianlu Wang; Jiayi Xin; Rui Zhang; Mari Ostendorf; Luke Zettlemoyer; Noah A. Smith; Tao Yu,International Conference on Learning Representations,261,https://www.semanticscholar.org/paper/86d0d3855f94105e25d81cab9f3d269c6062a9c4
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,18bd22b1b6091bec3c4b8f51ef97c7f11d7f110e,CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment,2022,Haoyu Song; Li Dong; Weinan Zhang; Ting Liu; Furu Wei,Annual Meeting of the Association for Computational Linguistics,139,https://www.semanticscholar.org/paper/18bd22b1b6091bec3c4b8f51ef97c7f11d7f110e
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,41cc3338635cde85316a0bcb934bffc73008761a,Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks,2023,Zhaohan Xi; Tianyu Du; Changjiang Li; Ren Pang; S. Ji; Jinghui Chen; Fenglong Ma; Ting Wang,Neural Information Processing Systems,32,https://www.semanticscholar.org/paper/41cc3338635cde85316a0bcb934bffc73008761a
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,03651ef144d2f28583541f81056835a16aacfcac,VERT: Verified Equivalent Rust Transpilation with Large Language Models as Few-Shot Learners,2024,Aidan Z.H. Yang; Yoshiki Takashima; Brandon Paulsen; J. Dodds; Daniel Kroening,,12,https://www.semanticscholar.org/paper/03651ef144d2f28583541f81056835a16aacfcac
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,5e8dd82419f78025093acbec3ba2e345fff85d11,Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs,2023,Jiaoayan Chen; Luyi Ma; Xiaohan Li; Nikhil Thakurdesai; Jianpeng Xu; Jason H. D. Cho; Kaushiki Nag; Evren Korpeoglu; Sushant Kumar; Kannan Achan,arXiv.org,28,https://www.semanticscholar.org/paper/5e8dd82419f78025093acbec3ba2e345fff85d11
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,39e40821b7207125e54e6ed7112e55cd38c6f0c3,Language Models of Code are Few-Shot Commonsense Learners,2022,Aman Madaan; Shuyan Zhou; Uri Alon; Yiming Yang; Graham Neubig,Conference on Empirical Methods in Natural Language Processing,221,https://www.semanticscholar.org/paper/39e40821b7207125e54e6ed7112e55cd38c6f0c3
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,f17d331a7a337dcf878969c9dab2e2c1a9e3b4ef,Making Pre-trained Language Models End-to-end Few-shot Learners with Contrastive Prompt Tuning,2022,Ziyun Xu; Chengyu Wang; Minghui Qiu; Fuli Luo; Runxin Xu; Songfang Huang; Jun Huang,Web Search and Data Mining,33,https://www.semanticscholar.org/paper/f17d331a7a337dcf878969c9dab2e2c1a9e3b4ef
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,de5a1a9014edc8dcba37735e4b5ecc385ddc2d55,Seal: Advancing Speech Language Models to be Few-Shot Learners,2024,Shuyu Lei; Lingen Liu; Jiaolong Yang; Yasen Jiao; Yuxiang Yang; Yushu Yang; Xiang Guo,arXiv.org,0,https://www.semanticscholar.org/paper/de5a1a9014edc8dcba37735e4b5ecc385ddc2d55
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,697aad9ef06add41b7f25e7bc671976c48ac68ad,Making Large Vision Language Models to be Good Few-shot Learners,2024,Fan Liu; Wenwen Cai; Jian Huo; Chuanyi Zhang; Delong Chen; Jun Zhou,AAAI Conference on Artificial Intelligence,0,https://www.semanticscholar.org/paper/697aad9ef06add41b7f25e7bc671976c48ac68ad
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,e1ff3202f8a8cb9d0813531ed3a7a487c6279ec8,Focused Large Language Models are Stable Many-Shot Learners,2024,Peiwen Yuan; Shaoxiong Feng; Yiwei Li; Xinglin Wang; Yueqi Zhang; Chuyi Tan; Boyuan Pan; Heda Wang; Yao Hu; Kan Li,Conference on Empirical Methods in Natural Language Processing,5,https://www.semanticscholar.org/paper/e1ff3202f8a8cb9d0813531ed3a7a487c6279ec8
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,b97b2b4dd9068e57ae194f492343ed8dfb1288b8,Unified Prompt Learning Makes Pre-Trained Language Models Better Few-Shot Learners,2023,Feihu Jin; Jinliang Lu; Jiajun Zhang,"IEEE International Conference on Acoustics, Speech, and Signal Processing",9,https://www.semanticscholar.org/paper/b97b2b4dd9068e57ae194f492343ed8dfb1288b8
2025-06-21T01-26-29-807Z.csv,searchPapers,Language Models are Few Shot Learners,c1ace33daf974d3d16752c7a8565f32a63b09c49,Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners,2022,Zhenhailong Wang; Manling Li; Ruochen Xu; Luowei Zhou; Jie Lei; Xudong Lin; Shuohang Wang; Ziyi Yang; Chenguang Zhu; Derek Hoiem; Shih-Fu Chang; Mohit Bansal; Heng Ji,Neural Information Processing Systems,142,https://www.semanticscholar.org/paper/c1ace33daf974d3d16752c7a8565f32a63b09c49
